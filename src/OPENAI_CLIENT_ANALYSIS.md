# OpenAI å®¢æˆ·ç«¯åˆ›å»ºä»£ç åˆ†ææŠ¥å‘Š

## ğŸ“‹ æ£€æŸ¥ç»“æœ

### âœ… å…³é”®å‘ç°

**ä»£ç ä¸­æ²¡æœ‰ä½¿ç”¨ `new OpenAI()` æˆ– OpenAI SDK**

æ•´ä¸ªé¡¹ç›®ä½¿ç”¨ **åŸç”Ÿ `fetch` API** ç›´æ¥è°ƒç”¨ OpenAI APIï¼Œè€Œä¸æ˜¯ä½¿ç”¨å®˜æ–¹çš„ `openai` npm åŒ…ã€‚

---

## ğŸ” è¯¦ç»†ä»£ç åˆ†æ

### 1. ä¸»è¦ OpenAI API è°ƒç”¨ä½ç½®

#### ä½ç½® 1: `app/api/llm/chat/route.ts`ï¼ˆåå‘ä»£ç†è·¯ç”±ï¼‰

è¿™æ˜¯**å”¯ä¸€çš„ OpenAI API ç›´æ¥è°ƒç”¨ç‚¹**ï¼Œä½¿ç”¨åŸç”Ÿ `fetch`ï¼š

```3:3:app/api/llm/chat/route.ts
const BASE_URL = process.env.PENAI_BASE_URL ?? process.env.OPENAI_BASE_URL ?? "https://api.openai.com";
```

```36:61:app/api/llm/chat/route.ts
export async function POST(req: NextRequest) {
  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey) {
    console.error("[LLM] proxy error: Missing OPENAI_API_KEY");
    return NextResponse.json(
      { error: "llm_proxy_failed", message: "LLM service not configured" },
      { status: 500 }
    );
  }

  try {
    const body = await req.json();
    const startTime = Date.now();

    const res = await fetchWithTimeout(
      `${BASE_URL}/v1/chat/completions`,
      {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${apiKey}`,
        },
        body: JSON.stringify(body),
      },
      LLM_TIMEOUT_MS
    );
```

#### ä½ç½® 2: `lib/llm/service.ts`ï¼ˆæœåŠ¡å±‚ï¼‰

è¿™ä¸ªæ–‡ä»¶**ä¸ç›´æ¥è°ƒç”¨ OpenAI API**ï¼Œè€Œæ˜¯é€šè¿‡å†…éƒ¨ä»£ç†è·¯ç”± `/api/llm/chat` è°ƒç”¨ï¼š

```161:209:lib/llm/service.ts
  private async callOpenAI(
    messages: LLMMessage[],
    options: { temperature: number; max_tokens: number; apiKey: string; model?: string; baseURL?: string },
  ): Promise<LLMResponse> {
    const { temperature, max_tokens, model = "gpt-4o-mini", baseURL } = options;
    
    // å¦‚æœæŒ‡å®šäº† baseURLï¼Œç›´æ¥è°ƒç”¨ OpenAI APIï¼ˆå…¼å®¹æ—§è¡Œä¸ºï¼Œç”¨äºè‡ªå®šä¹‰ç«¯ç‚¹ï¼‰
    if (baseURL) {
      const url = baseURL.endsWith("/chat/completions") ? baseURL : `${baseURL}/chat/completions`;
      return this.callOpenAIDirect(url, messages, { temperature, max_tokens, model });
    }

    // å¦åˆ™ä½¿ç”¨å†…éƒ¨ä»£ç†è·¯ç”± /api/llm/chatï¼ˆEdge Runtimeï¼‰
    // æ³¨æ„ï¼šæ‰€æœ‰ LLM è°ƒç”¨ç»Ÿä¸€é€šè¿‡åç«¯ APIï¼Œä¸åœ¨å‰ç«¯ç›´æ¥è°ƒç”¨
    const proxyUrl = getLLMProxyUrl();

    const response = await fetch(proxyUrl, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model,
        messages: messages.map((msg) => ({
          role: msg.role,
          content: msg.content,
        })),
        temperature,
        max_tokens,
      }),
    });

    if (!response.ok) {
      const error = await response.json().catch(() => ({ error: { message: "Unknown error" } }));
      throw new Error(`LLM proxy error: ${error.error || response.statusText}`);
    }

    const data = await response.json();
    return {
      content: data.choices[0]?.message?.content || "",
      usage: data.usage
        ? {
            prompt_tokens: data.usage.prompt_tokens,
            completion_tokens: data.usage.completion_tokens,
            total_tokens: data.usage.total_tokens,
          }
        : undefined,
    };
  }

  // ç›´æ¥è°ƒç”¨ OpenAI API çš„æ–¹æ³•ï¼ˆç”¨äºå…¼å®¹ baseURL é…ç½®ï¼‰
  private async callOpenAIDirect(
    url: string,
    messages: LLMMessage[],
    options: { temperature: number; max_tokens: number; model: string },
  ): Promise<LLMResponse> {
    const { temperature, max_tokens, model } = options;
    const apiKey = process.env.OPENAI_API_KEY;

    if (!apiKey) {
      throw new Error("OPENAI_API_KEY is required for direct OpenAI calls");
    }

    const response = await fetch(url, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${apiKey}`,
      },
      body: JSON.stringify({
        model,
        messages: messages.map((msg) => ({
          role: msg.role,
          content: msg.content,
        })),
        temperature,
        max_tokens,
      }),
    });
```

---

## ğŸ”‘ ç¯å¢ƒå˜é‡ä½¿ç”¨æƒ…å†µ

### ä½¿ç”¨çš„ç¯å¢ƒå˜é‡

#### 1. `OPENAI_API_KEY`ï¼ˆå¿…éœ€ï¼‰
- **ä½ç½®**: `app/api/llm/chat/route.ts:37`
- **ç”¨é€”**: OpenAI API è®¤è¯å¯†é’¥
- **ç±»å‹**: å¿…éœ€

```37:37:app/api/llm/chat/route.ts
  const apiKey = process.env.OPENAI_API_KEY;
```

#### 2. `PENAI_BASE_URL`ï¼ˆå¯é€‰ï¼Œä¼˜å…ˆçº§æœ€é«˜ï¼‰
- **ä½ç½®**: `app/api/llm/chat/route.ts:3`
- **ç”¨é€”**: è‡ªå®šä¹‰ OpenAI API Base URLï¼ˆPenAI ä»£ç†ï¼‰
- **ç±»å‹**: å¯é€‰
- **ä¼˜å…ˆçº§**: **1ï¼ˆæœ€é«˜ï¼‰**

#### 3. `OPENAI_BASE_URL`ï¼ˆå¯é€‰ï¼Œä¼˜å…ˆçº§ç¬¬äºŒï¼‰
- **ä½ç½®**: `app/api/llm/chat/route.ts:3`
- **ç”¨é€”**: è‡ªå®šä¹‰ OpenAI API Base URL
- **ç±»å‹**: å¯é€‰
- **ä¼˜å…ˆçº§**: **2**

#### 4. `LLM_TIMEOUT_MS`ï¼ˆå¯é€‰ï¼‰
- **ä½ç½®**: `app/api/llm/chat/route.ts:4`
- **ç”¨é€”**: LLM è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
- **é»˜è®¤å€¼**: `12000`ï¼ˆ12 ç§’ï¼‰
- **ç±»å‹**: å¯é€‰

```4:4:app/api/llm/chat/route.ts
const LLM_TIMEOUT_MS = parseInt(process.env.LLM_TIMEOUT_MS || "12000", 10); // é»˜è®¤ 12 ç§’ï¼ˆ10-15 ç§’èŒƒå›´ï¼‰
```

#### 5. `OPENAI_MODEL`ï¼ˆå¯é€‰ï¼Œä»…åœ¨ `lib/llm/service.ts` ä¸­ä½¿ç”¨ï¼‰
- **ä½ç½®**: `lib/llm/service.ts:317`
- **ç”¨é€”**: é»˜è®¤ OpenAI æ¨¡å‹
- **é»˜è®¤å€¼**: `"gpt-4o-mini"`
- **ç±»å‹**: å¯é€‰

```317:317:lib/llm/service.ts
      model: process.env.OPENAI_MODEL || "gpt-4o-mini",
```

---

## ğŸ“Š Base URL å–å€¼é¡ºåºï¼ˆä¼˜å…ˆçº§ï¼‰

### åœ¨ `app/api/llm/chat/route.ts` ä¸­

```3:3:app/api/llm/chat/route.ts
const BASE_URL = process.env.PENAI_BASE_URL ?? process.env.OPENAI_BASE_URL ?? "https://api.openai.com";
```

**ä¼˜å…ˆçº§é¡ºåº**ï¼š
1. **`PENAI_BASE_URL`**ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
2. **`OPENAI_BASE_URL`**ï¼ˆç¬¬äºŒä¼˜å…ˆçº§ï¼‰
3. **`"https://api.openai.com"`**ï¼ˆé»˜è®¤å€¼ï¼Œæœ€ä½ä¼˜å…ˆçº§ï¼‰

### åœ¨ `lib/llm/service.ts` ä¸­

```318:318:lib/llm/service.ts
      baseURL: process.env.OPENAI_BASE_URL,
```

**ä¼˜å…ˆçº§é¡ºåº**ï¼š
1. **`OPENAI_BASE_URL`**ï¼ˆå¦‚æœè®¾ç½®ï¼‰
2. **ä½¿ç”¨å†…éƒ¨ä»£ç†è·¯ç”± `/api/llm/chat`**ï¼ˆå¦‚æœæœªè®¾ç½® baseURLï¼‰

---

## ğŸ” åå‘ä»£ç†è·¯ç”±æ£€æŸ¥

### âœ… å­˜åœ¨çš„åå‘ä»£ç†è·¯ç”±

#### `/api/llm/chat`ï¼ˆä¸»è¦ä»£ç†è·¯ç”±ï¼‰

- **æ–‡ä»¶**: `app/api/llm/chat/route.ts`
- **ç”¨é€”**: ç»Ÿä¸€çš„ LLM ä»£ç†å…¥å£
- **ç‰¹ç‚¹**:
  - ä½¿ç”¨ Edge Runtime
  - æ”¯æŒè¶…æ—¶æ§åˆ¶ï¼ˆé»˜è®¤ 12 ç§’ï¼‰
  - æ”¯æŒè‡ªå®šä¹‰ Base URLï¼ˆ`PENAI_BASE_URL` æˆ– `OPENAI_BASE_URL`ï¼‰
  - ç»Ÿä¸€é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•

### âŒ ä¸å­˜åœ¨çš„è·¯ç”±

- **`/api/openai`** - **ä¸å­˜åœ¨**
- **`/api/penai`** - **ä¸å­˜åœ¨**

---

## ğŸ” ç¡¬ç¼–ç åŸŸåæ£€æŸ¥

### âœ… å‘ç°çš„ç¡¬ç¼–ç 

#### 1. OpenAI å®˜æ–¹ API åŸŸåï¼ˆé»˜è®¤å€¼ï¼‰

```3:3:app/api/llm/chat/route.ts
const BASE_URL = process.env.PENAI_BASE_URL ?? process.env.OPENAI_BASE_URL ?? "https://api.openai.com";
```

- **ä½ç½®**: `app/api/llm/chat/route.ts:3`
- **ç”¨é€”**: ä½œä¸ºé»˜è®¤ Base URLï¼ˆå½“ç¯å¢ƒå˜é‡æœªè®¾ç½®æ—¶ï¼‰
- **ç±»å‹**: ç¡¬ç¼–ç é»˜è®¤å€¼
- **æ˜¯å¦å¯é…ç½®**: âœ… å¯é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–

#### 2. Anthropic API åŸŸåï¼ˆç¡¬ç¼–ç ï¼‰

```269:269:lib/llm/service.ts
    const response = await fetch("https://api.anthropic.com/v1/messages", {
```

- **ä½ç½®**: `lib/llm/service.ts:269`
- **ç”¨é€”**: Anthropic Claude API è°ƒç”¨
- **ç±»å‹**: ç¡¬ç¼–ç 
- **æ˜¯å¦å¯é…ç½®**: âŒ ä¸å¯é…ç½®ï¼ˆä½† Anthropic ä¸åœ¨æœ¬æ¬¡æ£€æŸ¥èŒƒå›´å†…ï¼‰

### âŒ æœªå‘ç°çš„ç¡¬ç¼–ç 

- **`https://api.pen.ai`** - **ä¸å­˜åœ¨**
- **å…¶ä»–ä»£ç†åŸŸå** - **ä¸å­˜åœ¨**

---

## ğŸ“ æ€»ç»“

### âœ… ä»£ç æ¶æ„

1. **ä¸ä½¿ç”¨ OpenAI SDK**: é¡¹ç›®ä½¿ç”¨åŸç”Ÿ `fetch` APIï¼Œè€Œä¸æ˜¯ `openai` npm åŒ…
2. **ç»Ÿä¸€ä»£ç†å…¥å£**: æ‰€æœ‰ LLM è°ƒç”¨é€šè¿‡ `/api/llm/chat` è·¯ç”±
3. **æ”¯æŒè‡ªå®šä¹‰ Base URL**: é€šè¿‡ `PENAI_BASE_URL` æˆ– `OPENAI_BASE_URL` ç¯å¢ƒå˜é‡

### âœ… ç¯å¢ƒå˜é‡é…ç½®

| ç¯å¢ƒå˜é‡ | ä¼˜å…ˆçº§ | å¿…éœ€ | é»˜è®¤å€¼ | ç”¨é€” |
|---------|--------|------|--------|------|
| `OPENAI_API_KEY` | - | âœ… å¿…éœ€ | - | API è®¤è¯å¯†é’¥ |
| `PENAI_BASE_URL` | 1ï¼ˆæœ€é«˜ï¼‰ | âŒ å¯é€‰ | - | PenAI ä»£ç† Base URL |
| `OPENAI_BASE_URL` | 2 | âŒ å¯é€‰ | - | è‡ªå®šä¹‰ OpenAI Base URL |
| `LLM_TIMEOUT_MS` | - | âŒ å¯é€‰ | `12000` | è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰ |
| `OPENAI_MODEL` | - | âŒ å¯é€‰ | `"gpt-4o-mini"` | é»˜è®¤æ¨¡å‹ |

### âœ… Base URL å–å€¼é¡ºåº

```
PENAI_BASE_URL > OPENAI_BASE_URL > "https://api.openai.com"
```

### âœ… åå‘ä»£ç†è·¯ç”±

- âœ… `/api/llm/chat` - å­˜åœ¨ï¼ˆä¸»è¦ä»£ç†è·¯ç”±ï¼‰
- âŒ `/api/openai` - ä¸å­˜åœ¨
- âŒ `/api/penai` - ä¸å­˜åœ¨

### âœ… ç¡¬ç¼–ç åŸŸå

- âœ… `https://api.openai.com` - å­˜åœ¨ï¼ˆä½œä¸ºé»˜è®¤å€¼ï¼Œå¯é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰
- âŒ `https://api.pen.ai` - ä¸å­˜åœ¨
- âŒ å…¶ä»–ä»£ç†åŸŸå - ä¸å­˜åœ¨

---

## ğŸ¯ ç»“è®º

1. **ä»£ç ä¸­æ²¡æœ‰ä½¿ç”¨ `new OpenAI()`**ï¼Œè€Œæ˜¯ä½¿ç”¨åŸç”Ÿ `fetch` API
2. **Base URL é…ç½®çµæ´»**ï¼Œæ”¯æŒ `PENAI_BASE_URL` å’Œ `OPENAI_BASE_URL` ç¯å¢ƒå˜é‡
3. **æ²¡æœ‰ `/api/openai` è·¯ç”±**ï¼Œåªæœ‰ `/api/llm/chat` ä»£ç†è·¯ç”±
4. **æ²¡æœ‰ç¡¬ç¼–ç çš„ä»£ç†åŸŸå**ï¼ˆå¦‚ `api.pen.ai`ï¼‰ï¼Œåªæœ‰ OpenAI å®˜æ–¹ API çš„é»˜è®¤å€¼

